{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SdF8G_jfwcL6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import numpy\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words_id = list(set(stopwords.words('indonesian')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "pzSCpBsrw4AZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haters bacot tapi masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>akhirnya opening yg sangat gw tunggu</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>akhirnya pake intro ini lagi v</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>akhirnya pake intro lama lagi</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>akhirnya pake intro legend lagi ea</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>akhirnya pke intro itu lagi</td>\n",
              "      <td>positif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    text sentiment\n",
              "0         haters bacot tapi masih nonton   negatif\n",
              "1                          mantap kontol   negatif\n",
              "2                                  setan   negatif\n",
              "3                                    tai   negatif\n",
              "4                                  titit   negatif\n",
              "..                                   ...       ...\n",
              "95  akhirnya opening yg sangat gw tunggu   negatif\n",
              "96        akhirnya pake intro ini lagi v   positif\n",
              "97         akhirnya pake intro lama lagi   positif\n",
              "98    akhirnya pake intro legend lagi ea   positif\n",
              "99           akhirnya pke intro itu lagi   positif\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "df[['text', 'sentiment']] = df[['text', 'sentiment']].astype(str).fillna('')\n",
        "df = df[['text', 'sentiment']]\n",
        "df.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY9QP0VZzdBg"
      },
      "source": [
        "# **1. Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjopcnR0xxh_",
        "outputId": "39e12223-6af9-42df-b9b0-3fc8725df82f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop_duplicates(subset='text')\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "lPM4v6HbyF9w",
        "outputId": "58ab5f88-c942-42b1-913d-5f24f1919dcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haters bacot tapi masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yg komen beli subcriber bego kali y mikir kamu...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtube emang ada atur buat konten yg baik did...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10918</th>\n",
              "      <td>youtuber paling jujur kocak haters bikin eriko...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text sentiment\n",
              "0                         haters bacot tapi masih nonton   negatif\n",
              "1                                          mantap kontol   negatif\n",
              "2                                                  setan   negatif\n",
              "3                                                    tai   negatif\n",
              "4                                                  titit   negatif\n",
              "...                                                  ...       ...\n",
              "10914  yg komen beli subcriber bego kali y mikir kamu...   negatif\n",
              "10915  yo bangsat cakep aku suka kamu semangat bang t...   negatif\n",
              "10916                         yo lah anak pantek ang mah   negatif\n",
              "10917  youtube emang ada atur buat konten yg baik did...   negatif\n",
              "10918  youtuber paling jujur kocak haters bikin eriko...   negatif\n",
              "\n",
              "[10919 rows x 2 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna()\n",
        "df.isnull().sum()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": true,
        "id": "9FXNfrdtyxrO"
      },
      "outputs": [],
      "source": [
        "def clean_data(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FdL-OxrcK3aq",
        "outputId": "3815c18f-9232-49d8-eae1-32d950959f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haters bacot tapi masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yg komen beli subcriber bego kali y mikir kamu...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtube emang ada atur buat konten yg baik did...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10918</th>\n",
              "      <td>youtuber paling jujur kocak haters bikin eriko...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text sentiment\n",
              "0                         haters bacot tapi masih nonton   negatif\n",
              "1                                          mantap kontol   negatif\n",
              "2                                                  setan   negatif\n",
              "3                                                    tai   negatif\n",
              "4                                                  titit   negatif\n",
              "...                                                  ...       ...\n",
              "10914  yg komen beli subcriber bego kali y mikir kamu...   negatif\n",
              "10915  yo bangsat cakep aku suka kamu semangat bang t...   negatif\n",
              "10916                         yo lah anak pantek ang mah   negatif\n",
              "10917  youtube emang ada atur buat konten yg baik did...   negatif\n",
              "10918  youtuber paling jujur kocak haters bikin eriko...   negatif\n",
              "\n",
              "[10919 rows x 2 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Case Folding\n",
        "df['text'] = df['text'].str.lower()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ikg-DuCwa-Li",
        "outputId": "d54c85d0-9473-467f-e7ab-46883b0fde4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pembenci bacot tapi masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yg komentar beli subcriber bego kali y pikir k...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtube emang ada atur buat konten yg baik did...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10918</th>\n",
              "      <td>youtuber paling jujur kocak pembenci buat erik...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text sentiment\n",
              "0                       pembenci bacot tapi masih nonton   negatif\n",
              "1                                          mantap kontol   negatif\n",
              "2                                                  setan   negatif\n",
              "3                                                    tai   negatif\n",
              "4                                                  titit   negatif\n",
              "...                                                  ...       ...\n",
              "10914  yg komentar beli subcriber bego kali y pikir k...   negatif\n",
              "10915  yo bangsat cakep aku suka kamu semangat bang t...   negatif\n",
              "10916                         yo lah anak pantek ang mah   negatif\n",
              "10917  youtube emang ada atur buat konten yg baik did...   negatif\n",
              "10918  youtuber paling jujur kocak pembenci buat erik...   negatif\n",
              "\n",
              "[10919 rows x 2 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def normalize(text):\n",
        "    def load_normalization_dict():\n",
        "        with open('normalization_dict.json', 'r') as file:\n",
        "            normalization_dict = json.load(file)\n",
        "        return normalization_dict\n",
        "    normalization_dict = load_normalization_dict()\n",
        "    for word, replacement in normalization_dict.items():\n",
        "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].astype(str).apply(lambda x: normalize(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stopword Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "sqFI_LFdVkS3",
        "outputId": "b4614f3a-4564-47c0-f33d-70c47061b693"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pembenci bacot masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yg komentar beli subcriber bego kali y pikir k...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtube emang atur buat konten yg baik didik y...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10918</th>\n",
              "      <td>youtuber paling jujur kocak pembenci buat erik...</td>\n",
              "      <td>negatif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text sentiment\n",
              "0                            pembenci bacot masih nonton   negatif\n",
              "1                                          mantap kontol   negatif\n",
              "2                                                  setan   negatif\n",
              "3                                                    tai   negatif\n",
              "4                                                  titit   negatif\n",
              "...                                                  ...       ...\n",
              "10914  yg komentar beli subcriber bego kali y pikir k...   negatif\n",
              "10915  yo bangsat cakep aku suka kamu semangat bang t...   negatif\n",
              "10916                         yo lah anak pantek ang mah   negatif\n",
              "10917  youtube emang atur buat konten yg baik didik y...   negatif\n",
              "10918  youtuber paling jujur kocak pembenci buat erik...   negatif\n",
              "\n",
              "[10919 rows x 2 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import Sastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
        "more_stop_words = ['kok', 'cuk','v', 'sih', 'kan', 'loh', 'duh', 'wah', 'yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'sehingga', 'kembali', 'dan', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'setelah', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'apakah', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun', 'sekali', 'jadi', 'nya']\n",
        "stop_words = StopWordRemoverFactory().get_stop_words()\n",
        "stop_words.extend(more_stop_words)\n",
        "\n",
        "new_array = ArrayDictionary(stop_words)\n",
        "stop_words_remover_new = StopWordRemover(new_array)\n",
        "\n",
        "def stopword_removal(str_text):\n",
        "    str_text = stop_words_remover_new.remove(str_text)\n",
        "    return str_text\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: stopword_removal(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pembenci bacot masih nonton</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[pembenci, bacot, masih, nonton]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[mantap, kontol]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[setan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[tai]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[titit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yg komentar beli subcriber bego kali y pikir k...</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[yg, komentar, beli, subcriber, bego, kali, y,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[yo, bangsat, cakep, aku, suka, kamu, semangat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[yo, lah, anak, pantek, ang, mah]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtube emang atur buat konten yg baik didik y...</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[youtube, emang, atur, buat, konten, yg, baik,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10918</th>\n",
              "      <td>youtuber paling jujur kocak pembenci buat erik...</td>\n",
              "      <td>negatif</td>\n",
              "      <td>[youtuber, paling, jujur, kocak, pembenci, bua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10919 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text sentiment  \\\n",
              "0                            pembenci bacot masih nonton   negatif   \n",
              "1                                          mantap kontol   negatif   \n",
              "2                                                  setan   negatif   \n",
              "3                                                    tai   negatif   \n",
              "4                                                  titit   negatif   \n",
              "...                                                  ...       ...   \n",
              "10914  yg komentar beli subcriber bego kali y pikir k...   negatif   \n",
              "10915  yo bangsat cakep aku suka kamu semangat bang t...   negatif   \n",
              "10916                         yo lah anak pantek ang mah   negatif   \n",
              "10917  youtube emang atur buat konten yg baik didik y...   negatif   \n",
              "10918  youtuber paling jujur kocak pembenci buat erik...   negatif   \n",
              "\n",
              "                                               tokenized  \n",
              "0                       [pembenci, bacot, masih, nonton]  \n",
              "1                                       [mantap, kontol]  \n",
              "2                                                [setan]  \n",
              "3                                                  [tai]  \n",
              "4                                                [titit]  \n",
              "...                                                  ...  \n",
              "10914  [yg, komentar, beli, subcriber, bego, kali, y,...  \n",
              "10915  [yo, bangsat, cakep, aku, suka, kamu, semangat...  \n",
              "10916                  [yo, lah, anak, pantek, ang, mah]  \n",
              "10917  [youtube, emang, atur, buat, konten, yg, baik,...  \n",
              "10918  [youtuber, paling, jujur, kocak, pembenci, bua...  \n",
              "\n",
              "[10919 rows x 3 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tokenized'] = df['text'].astype(str).apply(lambda x:x.split())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "MRxHF_eoclEV"
      },
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "def stemming(text_cleaning):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    return stemmer.stem(text_cleaning)\n",
        "\n",
        "df['stemmed'] = df['text'].astype(str).apply(stemming)\n",
        "df[['stemmed', 'sentiment']].to_csv('executed.csv', index=False, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "# import pandas as pd\n",
        "\n",
        "# factory = StemmerFactory()\n",
        "# stemmer = factory.create_stemmer()\n",
        "\n",
        "# def stemming(text_cleaning):\n",
        "#     try:\n",
        "#         if not text_cleaning or pd.isna(text_cleaning):\n",
        "#             return \"\"\n",
        "#         return stemmer.stem(text_cleaning)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing text: {text_cleaning}. Error: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# df['stemmed'] = df['tokenized'].astype(str).apply(stemming)\n",
        "# df['stemmed'].to_csv('executed.csv', index=False, encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from Sastrawi.Stenner.StemmerFactory import StemmerFactory\n",
        "\n",
        "# def stemming(text_cleaning):\n",
        "#     factory = StemmerFactory()\n",
        "#     stemmer = factory.create_stener()\n",
        "#     do = []\n",
        "#     for w in text_cleaning:\n",
        "#         dt = stemmer.stem(w)\n",
        "#         do.append(dt)\n",
        "#     d_clean = []\n",
        "#     d_clean = \" \".join(do)\n",
        "#     print(d_clean)\n",
        "#     return d_clean\n",
        "\n",
        "# tokenized = tokenized.apply(stemming)\n",
        "# tokenized.to_csv(\"\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>benci bacot masih nonton</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10913</th>\n",
              "      <td>yg komentar beli subcriber bego kali y pikir k...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yo bangsat cakep aku suka kamu semangat bang t...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo lah anak pantek ang mah</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>youtube emang atur buat konten yg baik didik y...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtuber paling jujur kocak benci buat eriko l...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10918 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 stemmed  sentiment\n",
              "0                               benci bacot masih nonton         -1\n",
              "1                                          mantap kontol         -1\n",
              "2                                                  setan         -1\n",
              "3                                                    tai         -1\n",
              "4                                                  titit         -1\n",
              "...                                                  ...        ...\n",
              "10913  yg komentar beli subcriber bego kali y pikir k...         -1\n",
              "10914  yo bangsat cakep aku suka kamu semangat bang t...         -1\n",
              "10915                         yo lah anak pantek ang mah         -1\n",
              "10916  youtube emang atur buat konten yg baik didik y...         -1\n",
              "10917  youtuber paling jujur kocak benci buat eriko l...         -1\n",
              "\n",
              "[10918 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('executed.csv', encoding='latin1')\n",
        "# df = df.dropna()\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Translate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: translate in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.6.1)\n",
            "Requirement already satisfied: click in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from translate) (8.1.7)\n",
            "Requirement already satisfied: lxml in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from translate) (5.3.0)\n",
            "Requirement already satisfied: requests in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from translate) (2.32.3)\n",
            "Requirement already satisfied: libretranslatepy==2.1.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from translate) (2.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->translate) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->translate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->translate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->translate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->translate) (2024.8.30)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install translate\n",
        "from translate import Translator\n",
        "\n",
        "def translate_id(text):\n",
        "    try:\n",
        "        translator = Translator(from_lang='en', to_lang=\"id\")\n",
        "        translation = translator.translate(text)\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        print(f\"Error in translation: {e}\")\n",
        "        return text\n",
        "\n",
        "df['stemmed'] = df['stemmed'].astype(str).apply(translate_id)\n",
        "df['stemmed'].to_csv('TranslatedSampleID.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk5Vli06fEvQ",
        "outputId": "106120ec-8410-4c9b-e72a-addb671ec048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: preprocessor in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: textblob in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.18.0.post0)\n",
            "Requirement already satisfied: nltk>=3.8 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (4.67.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: wordcloud in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (2.1.3)\n",
            "Requirement already satisfied: pillow in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: nltk in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install preprocessor\n",
        "%pip install textblob\n",
        "%pip install wordcloud\n",
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labeling</th>\n",
              "      <th>filtered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>benci bacot nonton</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>bacot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mantap kontol</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>kontol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setan</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>setan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tai</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>tai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titit</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>titit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10913</th>\n",
              "      <td>yg komentar beli subcriber bego kali y pikir c...</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>bego bego</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>yo bangsat cakep suka semangat bang tetep duku...</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>bangsat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10915</th>\n",
              "      <td>yo anak pantek ang mah</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>pantek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10916</th>\n",
              "      <td>youtube emang atur konten yg didik youtube atu...</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>tolol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10917</th>\n",
              "      <td>youtuber jujur kocak benci eriko lim kocak nga...</td>\n",
              "      <td>-1</td>\n",
              "      <td>kasar</td>\n",
              "      <td>gila</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10918 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 stemmed  sentiment labeling  \\\n",
              "0                                     benci bacot nonton         -1    kasar   \n",
              "1                                          mantap kontol         -1    kasar   \n",
              "2                                                  setan         -1    kasar   \n",
              "3                                                    tai         -1    kasar   \n",
              "4                                                  titit         -1    kasar   \n",
              "...                                                  ...        ...      ...   \n",
              "10913  yg komentar beli subcriber bego kali y pikir c...         -1    kasar   \n",
              "10914  yo bangsat cakep suka semangat bang tetep duku...         -1    kasar   \n",
              "10915                             yo anak pantek ang mah         -1    kasar   \n",
              "10916  youtube emang atur konten yg didik youtube atu...         -1    kasar   \n",
              "10917  youtuber jujur kocak benci eriko lim kocak nga...         -1    kasar   \n",
              "\n",
              "        filtered  \n",
              "0          bacot  \n",
              "1         kontol  \n",
              "2          setan  \n",
              "3            tai  \n",
              "4          titit  \n",
              "...          ...  \n",
              "10913  bego bego  \n",
              "10914    bangsat  \n",
              "10915     pantek  \n",
              "10916      tolol  \n",
              "10917       gila  \n",
              "\n",
              "[10918 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('executed.csv', encoding='latin1')\n",
        "# df = df.drop('Unnamed: 0', axis=1)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text) \n",
        "    text = text.lower().strip()             \n",
        "    words = text.split()                    \n",
        "    words = [word for word in words if word not in stop_words_id]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['stemmed'] = df['stemmed'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model 1**\n",
        "(Positif/Netral/Negatif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pin-q0gsequV"
      },
      "source": [
        " **2. Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "label = {'positif': 1, 'netral':0, 'negatif': -1}\n",
        "df['sentiment'] = df['sentiment'].map(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df['stemmed']\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pembagian test dan train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. TF-IDF Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stop_words_id)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words_id)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Akurasi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediksi Kalimat Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prediksiKalimatBaru(text):\n",
        "    teksBaru = vectorizer.transform([text])\n",
        "    prediksi = model.predict(teksBaru)\n",
        "\n",
        "    if prediksi[0] == 1: \n",
        "        sentiment = \"positif\"\n",
        "    elif prediksi[0] == 0: \n",
        "        sentiment = \"netral\"\n",
        "    else: \n",
        "        sentiment = \"negatif\"\n",
        "    return sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Contoh Penggunaan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "contohKalimat = \"saya membeli anjing\"\n",
        "print(f\"Teks: '{contohKalimat}' => Sentimen: {prediksiKalimatBaru(contohKalimat)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model 2**\n",
        "(kasar/tidak kasar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " **1. Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stemmed_Comments</th>\n",
              "      <th>Tokenized_Comments</th>\n",
              "      <th>ID_Comments</th>\n",
              "      <th>labeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rick kamu anak hasil kondom bocor</td>\n",
              "      <td>[rick, kamu, anak, hasil, kondom, bocor]</td>\n",
              "      <td>rick kamu anak hasil kondom bocor</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kakak sok pede</td>\n",
              "      <td>[kakak, sok, pede]</td>\n",
              "      <td>kakak sok pede</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>keren bang slow aku subscribe kontol eenak</td>\n",
              "      <td>[keren, bang, slow, aku, subscribe, kontol, ee...</td>\n",
              "      <td>keren bang slow aku subscribe kontol eenak</td>\n",
              "      <td>kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apa tangan mu tato</td>\n",
              "      <td>[apa, tangan, mu, tato]</td>\n",
              "      <td>apa tangan mu tato</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>muka kamu anjing aku rugi nonton youtube kamu ...</td>\n",
              "      <td>[muka, kamu, anjing, aku, rugi, nonton, youtub...</td>\n",
              "      <td>muka kamu anjing aku rugi nonton youtube kamu ...</td>\n",
              "      <td>kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10632</th>\n",
              "      <td>awal mula yutuber suksess</td>\n",
              "      <td>[awal, mula, yutuber, suksess]</td>\n",
              "      <td>awal mula yutuber suksess</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10633</th>\n",
              "      <td>aihh sedih tukang numpang promosi tolol bego g...</td>\n",
              "      <td>[aihh, sedih, tukang, numpang, promosi, tolol,...</td>\n",
              "      <td>aihh sedih tukang numpang promosi tolol bego g...</td>\n",
              "      <td>kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10634</th>\n",
              "      <td>mampir chanelku yg suka bokeb</td>\n",
              "      <td>[mampir, chanelku, yg, suka, bokeb]</td>\n",
              "      <td>mampir chanelku yg suka bokeb</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10635</th>\n",
              "      <td>makasih</td>\n",
              "      <td>[makasih]</td>\n",
              "      <td>makasih</td>\n",
              "      <td>tidak kasar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10636</th>\n",
              "      <td>kotak kota goblok</td>\n",
              "      <td>[kotak, kota, goblok]</td>\n",
              "      <td>kotak kota goblok</td>\n",
              "      <td>kasar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10637 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Stemmed_Comments  \\\n",
              "0                      rick kamu anak hasil kondom bocor   \n",
              "1                                         kakak sok pede   \n",
              "2             keren bang slow aku subscribe kontol eenak   \n",
              "3                                     apa tangan mu tato   \n",
              "4      muka kamu anjing aku rugi nonton youtube kamu ...   \n",
              "...                                                  ...   \n",
              "10632                          awal mula yutuber suksess   \n",
              "10633  aihh sedih tukang numpang promosi tolol bego g...   \n",
              "10634                      mampir chanelku yg suka bokeb   \n",
              "10635                                            makasih   \n",
              "10636                                  kotak kota goblok   \n",
              "\n",
              "                                      Tokenized_Comments  \\\n",
              "0               [rick, kamu, anak, hasil, kondom, bocor]   \n",
              "1                                     [kakak, sok, pede]   \n",
              "2      [keren, bang, slow, aku, subscribe, kontol, ee...   \n",
              "3                                [apa, tangan, mu, tato]   \n",
              "4      [muka, kamu, anjing, aku, rugi, nonton, youtub...   \n",
              "...                                                  ...   \n",
              "10632                     [awal, mula, yutuber, suksess]   \n",
              "10633  [aihh, sedih, tukang, numpang, promosi, tolol,...   \n",
              "10634                [mampir, chanelku, yg, suka, bokeb]   \n",
              "10635                                          [makasih]   \n",
              "10636                              [kotak, kota, goblok]   \n",
              "\n",
              "                                             ID_Comments     labeling  \n",
              "0                      rick kamu anak hasil kondom bocor  tidak kasar  \n",
              "1                                         kakak sok pede  tidak kasar  \n",
              "2             keren bang slow aku subscribe kontol eenak        kasar  \n",
              "3                                     apa tangan mu tato  tidak kasar  \n",
              "4      muka kamu anjing aku rugi nonton youtube kamu ...        kasar  \n",
              "...                                                  ...          ...  \n",
              "10632                          awal mula yutuber suksess  tidak kasar  \n",
              "10633  aihh sedih tukang numpang promosi tolol bego g...        kasar  \n",
              "10634                      mampir chanelku yg suka bokeb  tidak kasar  \n",
              "10635                                            makasih  tidak kasar  \n",
              "10636                                  kotak kota goblok        kasar  \n",
              "\n",
              "[10637 rows x 4 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('kamus_kasar.json', 'r') as file:\n",
        "    kamus = json.load(file)\n",
        "\n",
        "def labeling(text, kamus):\n",
        "    words = set(text.split())\n",
        "    kata_kasar = set(kamus.keys())  \n",
        "    if words & kata_kasar:\n",
        "        return 'kasar'\n",
        "    else:\n",
        "        return 'tidak kasar'\n",
        "    \n",
        "df['labeling'] = df['stemmed'].astype(str).apply(lambda x: labeling(x, kamus))\n",
        "df.to_csv('labeled.csv', encoding='latin1')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pembagian dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'stemmed'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'stemmed'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32md:\\(( Kuliah UMS ))\\Semester 7\\Skripsi\\code\\rudeword1\\model.ipynb Cell 46\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mstemmed\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mdropna() \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mlabeling\u001b[39m\u001b[39m'\u001b[39m]           \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'stemmed'"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['stemmed'].astype(str).dropna() \n",
        "y = df['labeling']           \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Jumlah data latih: {len(X_train)}\")\n",
        "print(f\"Jumlah data uji: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensi X_train_tfidf: (8509, 8579)\n",
            "Dimensi X_test_tfidf: (2128, 8579)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stemmed_Comments</th>\n",
              "      <th>Tokenized_Comments</th>\n",
              "      <th>ID_Comments</th>\n",
              "      <th>labeling</th>\n",
              "      <th>Filtered_Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rick kamu anak hasil kondom bocor</td>\n",
              "      <td>[rick, kamu, anak, hasil, kondom, bocor]</td>\n",
              "      <td>rick kamu anak hasil kondom bocor</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kakak sok pede</td>\n",
              "      <td>[kakak, sok, pede]</td>\n",
              "      <td>kakak sok pede</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>keren bang slow aku subscribe kontol eenak</td>\n",
              "      <td>[keren, bang, slow, aku, subscribe, kontol, ee...</td>\n",
              "      <td>keren bang slow aku subscribe kontol eenak</td>\n",
              "      <td>kasar</td>\n",
              "      <td>kontol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apa tangan mu tato</td>\n",
              "      <td>[apa, tangan, mu, tato]</td>\n",
              "      <td>apa tangan mu tato</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>muka kamu anjing aku rugi nonton youtube kamu ...</td>\n",
              "      <td>[muka, kamu, anjing, aku, rugi, nonton, youtub...</td>\n",
              "      <td>muka kamu anjing aku rugi nonton youtube kamu ...</td>\n",
              "      <td>kasar</td>\n",
              "      <td>anjing anjing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10632</th>\n",
              "      <td>awal mula yutuber suksess</td>\n",
              "      <td>[awal, mula, yutuber, suksess]</td>\n",
              "      <td>awal mula yutuber suksess</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10633</th>\n",
              "      <td>aihh sedih tukang numpang promosi tolol bego g...</td>\n",
              "      <td>[aihh, sedih, tukang, numpang, promosi, tolol,...</td>\n",
              "      <td>aihh sedih tukang numpang promosi tolol bego g...</td>\n",
              "      <td>kasar</td>\n",
              "      <td>tolol bego bangsat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10634</th>\n",
              "      <td>mampir chanelku yg suka bokeb</td>\n",
              "      <td>[mampir, chanelku, yg, suka, bokeb]</td>\n",
              "      <td>mampir chanelku yg suka bokeb</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10635</th>\n",
              "      <td>makasih</td>\n",
              "      <td>[makasih]</td>\n",
              "      <td>makasih</td>\n",
              "      <td>tidak kasar</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10636</th>\n",
              "      <td>kotak kota goblok</td>\n",
              "      <td>[kotak, kota, goblok]</td>\n",
              "      <td>kotak kota goblok</td>\n",
              "      <td>kasar</td>\n",
              "      <td>goblok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10637 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Stemmed_Comments  \\\n",
              "0                      rick kamu anak hasil kondom bocor   \n",
              "1                                         kakak sok pede   \n",
              "2             keren bang slow aku subscribe kontol eenak   \n",
              "3                                     apa tangan mu tato   \n",
              "4      muka kamu anjing aku rugi nonton youtube kamu ...   \n",
              "...                                                  ...   \n",
              "10632                          awal mula yutuber suksess   \n",
              "10633  aihh sedih tukang numpang promosi tolol bego g...   \n",
              "10634                      mampir chanelku yg suka bokeb   \n",
              "10635                                            makasih   \n",
              "10636                                  kotak kota goblok   \n",
              "\n",
              "                                      Tokenized_Comments  \\\n",
              "0               [rick, kamu, anak, hasil, kondom, bocor]   \n",
              "1                                     [kakak, sok, pede]   \n",
              "2      [keren, bang, slow, aku, subscribe, kontol, ee...   \n",
              "3                                [apa, tangan, mu, tato]   \n",
              "4      [muka, kamu, anjing, aku, rugi, nonton, youtub...   \n",
              "...                                                  ...   \n",
              "10632                     [awal, mula, yutuber, suksess]   \n",
              "10633  [aihh, sedih, tukang, numpang, promosi, tolol,...   \n",
              "10634                [mampir, chanelku, yg, suka, bokeb]   \n",
              "10635                                          [makasih]   \n",
              "10636                              [kotak, kota, goblok]   \n",
              "\n",
              "                                             ID_Comments     labeling  \\\n",
              "0                      rick kamu anak hasil kondom bocor  tidak kasar   \n",
              "1                                         kakak sok pede  tidak kasar   \n",
              "2             keren bang slow aku subscribe kontol eenak        kasar   \n",
              "3                                     apa tangan mu tato  tidak kasar   \n",
              "4      muka kamu anjing aku rugi nonton youtube kamu ...        kasar   \n",
              "...                                                  ...          ...   \n",
              "10632                          awal mula yutuber suksess  tidak kasar   \n",
              "10633  aihh sedih tukang numpang promosi tolol bego g...        kasar   \n",
              "10634                      mampir chanelku yg suka bokeb  tidak kasar   \n",
              "10635                                            makasih  tidak kasar   \n",
              "10636                                  kotak kota goblok        kasar   \n",
              "\n",
              "        Filtered_Comments  \n",
              "0                          \n",
              "1                          \n",
              "2                  kontol  \n",
              "3                          \n",
              "4           anjing anjing  \n",
              "...                   ...  \n",
              "10632                      \n",
              "10633  tolol bego bangsat  \n",
              "10634                      \n",
              "10635                      \n",
              "10636              goblok  \n",
              "\n",
              "[10637 rows x 5 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('kamus_kasar.json', 'r') as file:\n",
        "    kamus = json.load(file)\n",
        "\n",
        "kata_kasar = set(kamus.keys())\n",
        "\n",
        "def filter_kata_kasar(text, kamus_keys):\n",
        "    words = str(text).split()\n",
        "    filtered_words = [word for word in words if word in kamus_keys]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "df['filtered'] = df['stemmed'].apply(lambda x: filter_kata_kasar(x, kata_kasar))\n",
        "df.to_csv('executed.csv', index=False, encoding='latin1')\n",
        "# df[['stemmed', 'Filtered_Comments']]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hitung Skor TF-IDF per kata kasar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>TF-IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kontol</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anjing</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>babi</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>memek</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>goblok</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2778</th>\n",
              "      <td>perek</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2801</th>\n",
              "      <td>bangkai</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3037</th>\n",
              "      <td>tuyul</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3102</th>\n",
              "      <td>wong</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3656</th>\n",
              "      <td>antek</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Comments  TF-IDF\n",
              "0      kontol    1.00\n",
              "1      anjing    1.00\n",
              "6        babi    0.66\n",
              "8       memek    0.52\n",
              "11     goblok    0.36\n",
              "...       ...     ...\n",
              "2778    perek    0.86\n",
              "2801  bangkai    1.00\n",
              "3037    tuyul    0.80\n",
              "3102     wong    1.00\n",
              "3656    antek    0.97\n",
              "\n",
              "[81 rows x 2 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def filter_kata_kasar(text, kata_kasar):\n",
        "    words = str(text).split()\n",
        "    filtered_words = [word for word in words if word in kata_kasar]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Filtered_Comments'])\n",
        "\n",
        "features = vectorizer.get_feature_names_out()\n",
        "scores = tfidf_matrix.toarray()\n",
        "\n",
        "data = []\n",
        "for doc_idx, doc_scores in enumerate(scores):\n",
        "    tokens = [features[i] for i in range(len(features)) if doc_scores[i] > 0]\n",
        "    tfidf_scores = [round(doc_scores[i], 2) for i in range(len(features)) if doc_scores[i] > 0]\n",
        "    \n",
        "    for token, score in zip(tokens, tfidf_scores):\n",
        "        data.append({\"Comments\": token, \"TF-IDF\": score})\n",
        "\n",
        "df_tfidf = pd.DataFrame(data)\n",
        "df_tfidf = df_tfidf[df_tfidf['Comments'].str.len() > 0].dropna().drop_duplicates(subset='Comments')\n",
        "df_tfidf.to_csv(\"skor_tfidf.csv\", index=False)\n",
        "score = pd.read_csv(\"skor_tfidf.csv\", encoding='latin1')\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ambil skor TF-IDF diatas 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.DataFrame()\n",
        "data = df[df['TF-IDF'] > 0.5]\n",
        "data.to_csv('high_tfidf.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ambil kata yang TF-IDF diatas 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('high_tfidf.csv')\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "high_tfidf = data['Comments']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cek apakah ada kata TF-IDF tinggi dalam kalimat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cekTFIDF(text, data):\n",
        "    words = set(text.split())\n",
        "    high_tfidf = set(data)\n",
        "    if words & high_tfidf:\n",
        "        return 'ada'\n",
        "    else:\n",
        "        return 'tidak ada'\n",
        "    \n",
        "df['cekTF-IDF'] = df['text'].astype(str).apply(lambda x: cekTFIDF(x, data))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **3. Word Replacement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'kamus_kasar.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\(( Kuliah UMS ))\\Semester 7\\Skripsi\\code\\rudeword1\\model.ipynb Cell 63\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mkamus_kasar.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     kamus \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/model.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m kata_kasar \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(kamus)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kamus_kasar.json'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('kamus_kasar.json', 'r') as file:\n",
        "    kamus = json.load(file)\n",
        "\n",
        "def replace_kata_kasar(text, kamus):\n",
        "    words = text.split()  \n",
        "    word_replacement = [kamus[key] if key in kamus else key for key in words]\n",
        "    return ' '.join(word_replacement)\n",
        "\n",
        "df = pd.read_csv('executed.csv')\n",
        "df['text'] = df['stemmed'].astype(str)\n",
        "\n",
        "df['fixed'] = df.apply(\n",
        "    lambda row: replace_kata_kasar(row['text'], kamus) if row['sentiment'] != 'positif' else row['text'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df[['text', 'fixed']].to_csv('hasil.csv', encoding='latin1', index=False)\n",
        "dresult = pd.read_csv('hasil.csv')\n",
        "print(dresult)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluasi Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words_id = list(set(stopwords.words('indonesian')))\n",
        "\n",
        "data = pd.read_csv('hasil.csv')\n",
        "\n",
        "data = data.dropna(subset=['Comments', 'Replaced_Comments'])\n",
        "print(data.isnull().sum())\n",
        "\n",
        "X = data['Comments'] \n",
        "y = data['Replaced_Comments']    \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    min_df=2,     \n",
        "    max_df=0.95,\n",
        "    stop_words=stop_words_id\n",
        ")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(f\"Akurasi: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Eksekusi dalam input**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dasar manusia tidak pengertian\n"
          ]
        }
      ],
      "source": [
        "def execute(word):\n",
        "    word = clean_data(word)\n",
        "    word = normalize(word)\n",
        "    word = stemming(word)\n",
        "    word = translate_id(word)\n",
        "    word = replace_kata_kasar(word, kamus)\n",
        "    return word\n",
        "\n",
        "contoh = 'Dasar manusia tolol'\n",
        "execute(contoh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install dill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Saving Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "def clean_data(text):\n",
        "    import re\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "with open('clean_data.sav', 'wb') as file:\n",
        "    dill.dump(clean_data, file)\n",
        "\n",
        "def load_normalization_dict():\n",
        "    with open('normalization_dict.json', 'r') as file:\n",
        "        normalization_dict = json.load(file)\n",
        "    return normalization_dict\n",
        "\n",
        "def normalize(text):\n",
        "    import re, json\n",
        "    def load_normalization_dict():\n",
        "        with open('normalization_dict.json', 'r') as file:\n",
        "            normalization_dict = json.load(file)\n",
        "        return normalization_dict\n",
        "    normalization_dict = load_normalization_dict()\n",
        "    for word, replacement in normalization_dict.items():\n",
        "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text\n",
        "with open('normalize.sav', 'wb') as file:\n",
        "    dill.dump(normalize, file)\n",
        "\n",
        "def stemming(text_cleaning):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    return stemmer.stem(text_cleaning)\n",
        "with open('stemming.sav', 'wb') as file:\n",
        "    dill.dump(stemming, file)\n",
        "\n",
        "def translate_id(text):\n",
        "    try:\n",
        "        translator = Translator(from_lang='en', to_lang=\"id\" )\n",
        "        translation = translator.translate(text)\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        print(f\"Error in translation: {e}\")\n",
        "        return text\n",
        "with open('translate_id.sav', 'wb') as file:\n",
        "    dill.dump(translate_id, file)\n",
        "    \n",
        "def replace_kata_kasar(text):\n",
        "    import json\n",
        "    with open('kamus_kasar.json', 'r') as file:\n",
        "        kamus = json.load(file)\n",
        "        kata_kasar = set(kamus.keys())\n",
        "        words = text.split()\n",
        "        word_replacement = [kamus[key] if key in kata_kasar else key for key in words]\n",
        "    return ' '.join(word_replacement)\n",
        "with open('replace_kata_kasar.sav', 'wb') as file:\n",
        "    dill.dump(replace_kata_kasar, file) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "def execute(word):\n",
        "    word = clean_data(word)\n",
        "    word = normalize(word)\n",
        "    word = stemming(word)\n",
        "    word = translate_id(word)\n",
        "    word = replace_kata_kasar(word, kamus)\n",
        "    return word\n",
        "\n",
        "with open('execute_function.sav', 'wb') as file:\n",
        "    dill.dump(execute, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
