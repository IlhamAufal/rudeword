{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cukup.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (2024.8.30)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metode NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngilu anjeng</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anjing ericko lim bisa ngomong baik adddduuu g...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bang jangan kalah sama haters haters tu cuma b...</td>\n",
       "      <td>-0.7506</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gak peduli hatters kok bikin lagu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gw ngerti lu sibuk ngurusin ytr tapi lu coba b...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>zharborneo ikut rewind gk bang</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>zhiap bang saya juga</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>zigi wig tombol mode batas youtube</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>ziroaz didik nah emng main game main hp nonton...</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>zzzzzzzzzzzzzzzz hatres kalok ada giveway lu j...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10962 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment_score  \\\n",
       "0                                           ngilu anjeng           0.0000   \n",
       "1      anjing ericko lim bisa ngomong baik adddduuu g...           0.3612   \n",
       "2      bang jangan kalah sama haters haters tu cuma b...          -0.7506   \n",
       "3                      gak peduli hatters kok bikin lagu           0.0000   \n",
       "4      gw ngerti lu sibuk ngurusin ytr tapi lu coba b...           0.3612   \n",
       "...                                                  ...              ...   \n",
       "10957                     zharborneo ikut rewind gk bang           0.0000   \n",
       "10958                               zhiap bang saya juga           0.0000   \n",
       "10959                 zigi wig tombol mode batas youtube           0.0000   \n",
       "10960  ziroaz didik nah emng main game main hp nonton...          -0.2023   \n",
       "10961  zzzzzzzzzzzzzzzz hatres kalok ada giveway lu j...           0.0000   \n",
       "\n",
       "      sentiment  \n",
       "0        netral  \n",
       "1       positif  \n",
       "2       negatif  \n",
       "3        netral  \n",
       "4       positif  \n",
       "...         ...  \n",
       "10957    netral  \n",
       "10958    netral  \n",
       "10959    netral  \n",
       "10960   negatif  \n",
       "10961    netral  \n",
       "\n",
       "[10962 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "data = SentimentIntensityAnalyzer()\n",
    "\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "for text in df['text']:\n",
    "    if isinstance(text, str):\n",
    "        sentiment_scores = data.polarity_scores(text) \n",
    "        compound_score = sentiment_scores[\"compound\"]\n",
    "\n",
    "        scores.append(compound_score)\n",
    "\n",
    "        if compound_score > 0:\n",
    "            label = 'positif'\n",
    "        elif compound_score < 0:\n",
    "            label = 'negatif'\n",
    "        else:\n",
    "            label = 'netral'\n",
    "        \n",
    "        labels.append(label)\n",
    "    else:\n",
    "        scores.append(0)\n",
    "        labels.append('netral')\n",
    "\n",
    "df['sentiment_score'] = scores \n",
    "df['sentiment'] = labels\n",
    "\n",
    "data = df[['text', 'sentiment_score', 'sentiment']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metode TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
      "  Downloading hstspreload-2024.12.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2024.12.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.3 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (pyproject.toml): started\n",
      "  Building wheel for googletrans (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15777 sha256=55c1998e713e84c5aaa9242d0e00f9d223cc4f107c239c608d9d81de989eac1e\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\a0\\a7\\f5\\8029729ab74f860fab6614e312b0aa48b665d1057280bc2ef3\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.6\n",
      "    Uninstalling httpcore-1.0.6:\n",
      "      Successfully uninstalled httpcore-1.0.6\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.2.5 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob\n",
    "%pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\(( Kuliah UMS ))\\Semester 7\\Skripsi\\code\\rudeword1\\labelling.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m# Terjemahkan teks ke bahasa Inggris\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         translated_text \u001b[39m=\u001b[39m translator\u001b[39m.\u001b[39;49mtranslate(text, src\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m, dest\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mtext\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         blob \u001b[39m=\u001b[39m TextBlob(translated_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%28%28%20Kuliah%20UMS%20%29%29/Semester%207/Skripsi/code/rudeword1/labelling.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         polarity \u001b[39m=\u001b[39m blob\u001b[39m.\u001b[39msentiment\u001b[39m.\u001b[39mpolarity\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googletrans\\client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    181\u001b[0m origin \u001b[39m=\u001b[39m text\n\u001b[1;32m--> 182\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_translate(text, dest, src, kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[39m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m translated \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([d[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m d[\u001b[39m0\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googletrans\\client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[1;34m(self, text, dest, src, override)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_translate\u001b[39m(\u001b[39mself\u001b[39m, text, dest, src, override):\n\u001b[1;32m---> 78\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_acquirer\u001b[39m.\u001b[39;49mdo(text)\n\u001b[0;32m     79\u001b[0m     params \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mbuild_params(query\u001b[39m=\u001b[39mtext, src\u001b[39m=\u001b[39msrc, dest\u001b[39m=\u001b[39mdest,\n\u001b[0;32m     80\u001b[0m                                 token\u001b[39m=\u001b[39mtoken, override\u001b[39m=\u001b[39moverride)\n\u001b[0;32m     82\u001b[0m     url \u001b[39m=\u001b[39m urls\u001b[39m.\u001b[39mTRANSLATE\u001b[39m.\u001b[39mformat(host\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pick_service_url())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googletrans\\gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update()\n\u001b[0;32m    195\u001b[0m     tk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macquire(text)\n\u001b[0;32m    196\u001b[0m     \u001b[39mreturn\u001b[39;00m tk\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googletrans\\gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mRE_TKK\u001b[39m.\u001b[39;49msearch(r\u001b[39m.\u001b[39;49mtext)\u001b[39m.\u001b[39;49mgroup(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mvar \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[39m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m code \u001b[39m=\u001b[39m code\u001b[39m.\u001b[39mencode()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39municode-escape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "\n",
    "translator = Translator()\n",
    "scores = []\n",
    "labels = []\n",
    "\n",
    "for text in df['text']:\n",
    "    if isinstance(text, str):\n",
    "        translated_text = translator.translate(text, src='id', dest='en').text\n",
    "        blob = TextBlob(translated_text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "\n",
    "        if polarity > 0:\n",
    "            label = 'positif'\n",
    "        elif polarity < 0:\n",
    "            label = 'negatif'\n",
    "        else:\n",
    "            label = 'netral'\n",
    "\n",
    "        scores.append(polarity)\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        scores.append(0)\n",
    "        labels.append('netral')\n",
    "\n",
    "df['sentiment_score'] = scores\n",
    "df['sentiment'] = labels\n",
    "\n",
    "data = df[['text', 'sentiment_score', 'sentiment']]\n",
    "print(data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
